Our VTFF is built upon on two pre-trained ResNet18 [32] networks, and consists of two crucial components: i) attentional selective fusion, ii) multi-Layer Transformer encoder.For a given face image 𝐼𝑅𝐺𝐵 with the size of 𝐻 × 𝑊 × 3, we first get its LBP feature image with the size of 𝐻 × 𝑊 × 1 and concatenate it to a feature image 𝐼𝐿𝐵𝑃 with the size of 𝐻 ×𝑊 ×3. The feature extraction backbones are composed of two ResNet18 networks: one is for the RGB image and the other is for its LBP feature image. Particularly, we employ the first five stages of ResNet18 as the backbone to extract feature maps 𝑋𝐿𝐵𝑃 and 𝑋𝑅𝐺𝐵 with the size of 𝐻/𝑅 × 𝑊/𝑅 × 𝐶𝑓, where R is the downsampling rate of ResNet18, 𝐶𝑓 is the channel number of the output of the stage 5. For simplicity, we denote 𝐻𝑑 =𝐻/𝑅 and 𝑊𝑑 = 𝑊/𝑅. In this paper, 𝑅 = 32 and 𝐻 = 𝑊 = 224.